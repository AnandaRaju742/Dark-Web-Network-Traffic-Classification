{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":2607,"status":"ok","timestamp":1601699257815,"user":{"displayName":"Colab user","photoUrl":"","userId":"05675691712636553851"},"user_tz":-330},"id":"L9iE-oqOqj4h","outputId":"74aa7ff3-950e-4b9e-fe42-1ec473b9508f"},"outputs":[{"name":"stdout","output_type":"stream","text":["openjdk version \"11.0.8\" 2020-07-14\n","OpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1, mixed mode, sharing)\n"]}],"source":["import os       #importing os to set environment variable\n","def install_java():\n","  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n","  !java -version       #check java version\n","install_java()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":12310,"status":"ok","timestamp":1601699268482,"user":{"displayName":"Colab user","photoUrl":"","userId":"05675691712636553851"},"user_tz":-330},"id":"sTBOSxI0qmps","outputId":"001f3d8e-4f7a-4f6f-d691-6ed2e65b2408"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libproj-dev is already the newest version (4.9.3-2).\n","proj-bin is already the newest version (4.9.3-2).\n","proj-data is already the newest version (4.9.3-2).\n","0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libgeos-dev is already the newest version (3.6.2-1build2).\n","0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n","Requirement already satisfied: python-weka-wrapper3 in /usr/local/lib/python3.6/dist-packages (0.1.14)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from python-weka-wrapper3) (1.18.5)\n","Requirement already satisfied: javabridge>=1.0.14 in /usr/local/lib/python3.6/dist-packages (from python-weka-wrapper3) (1.0.19)\n","Requirement already satisfied: arff in /usr/local/lib/python3.6/dist-packages (0.9)\n"]}],"source":["!apt-get install libproj-dev proj-data proj-bin\n","!apt-get install libgeos-dev\n","!pip install cython\n","!pip install python-weka-wrapper3\n","!pip install arff"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":11060,"status":"ok","timestamp":1601699270015,"user":{"displayName":"Colab user","photoUrl":"","userId":"05675691712636553851"},"user_tz":-330},"id":"4XNb1bGxqtIg","outputId":"ae40922d-0168-413a-dfb7-ee063ffe3caf"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG:weka.core.jvm:Adding bundled jars\n","DEBUG:weka.core.jvm:Classpath=['/usr/local/lib/python3.6/dist-packages/javabridge/jars/rhino-1.7R4.jar', '/usr/local/lib/python3.6/dist-packages/javabridge/jars/runnablequeue.jar', '/usr/local/lib/python3.6/dist-packages/javabridge/jars/cpython.jar', '/usr/local/lib/python3.6/dist-packages/weka/lib/weka.jar', '/usr/local/lib/python3.6/dist-packages/weka/lib/python-weka-wrapper.jar']\n","DEBUG:weka.core.jvm:MaxHeapSize=25G\n","DEBUG:weka.core.jvm:Package support enabled\n"]}],"source":["import weka.core.jvm as jvm\n","jvm.start(packages=True,max_heap_size=\"25G\")\n","\n","from weka.core.converters import Loader\n","from weka.core.classes import Random\n","from weka.classifiers import Classifier, Evaluation"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"elapsed":300306,"status":"ok","timestamp":1601699677282,"user":{"displayName":"Colab user","photoUrl":"","userId":"05675691712636553851"},"user_tz":-330},"id":"Wca-4hcrsJa0","outputId":"6a54dfc9-10f6-4098-cfd6-8e8d3b4e9ee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+git://github.com/scikit-learn/scikit-learn.git\n","  Cloning git://github.com/scikit-learn/scikit-learn.git to /tmp/pip-req-build-gvreg9vb\n","  Running command git clone -q git://github.com/scikit-learn/scikit-learn.git /tmp/pip-req-build-gvreg9vb\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied (use --upgrade to upgrade): scikit-learn==0.24.dev0 from git+git://github.com/scikit-learn/scikit-learn.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (2.1.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (1.18.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.dev0) (0.16.0)\n","Building wheels for collected packages: scikit-learn\n","  Building wheel for scikit-learn (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn: filename=scikit_learn-0.24.dev0-cp36-cp36m-linux_x86_64.whl size=17615837 sha256=ddd4a1853e242cdddb611e2083ca28430a4782485ad638f262f8190f55b7099c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-c0dy0qy9/wheels/a1/50/0e/316ef2ff8d4cfade292bd20b49efda94727688a153382745a6\n","Successfully built scikit-learn\n"]}],"source":["!pip install git+git://github.com/scikit-learn/scikit-learn.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":3447,"status":"error","timestamp":1601700481689,"user":{"displayName":"Colab user","photoUrl":"","userId":"05675691712636553851"},"user_tz":-330},"id":"X7NZjYVjpX8K","outputId":"9a44402a-ccaa-4244-8c70-3f838d0e46c1"},"outputs":[],"source":["# !/usr/bin/python2\n","\n","#    Implements flat classifiers employed in the paper \"A Dive into the Dark Web: Hierarchical Traffic Classification of Anonymity Tools\".\n","#\n","#    Copyright (C) 2018  Giampaolo Bovenzi & Antonio Montieri\n","#    email: traffic@unina.it, giampaolo.bovenzi@gmail.com, antonio.montieri@unina.it\n","#\n","#    This program is free software: you can redistribute it and/or modify\n","#    it under the terms of the GNU Affero General Public License as\n","#    published by the Free Software Foundation, either version 3 of the\n","#    License, or (at your option) any later version.\n","#\n","#    This program is distributed in the hope that it will be useful,\n","#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n","#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","#    GNU Affero General Public License for more details.\n","#\n","#    You should have received a copy of the GNU Affero General Public License\n","#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n","\n","import arff\n","import numpy as np\n","import copy\n","import sys\n","import getopt\n","import os\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","import weka.core.jvm as jvm\n","from weka.core.converters import Loader, ndarray_to_instances\n","from weka.core.dataset import Instances, Attribute\n","from weka.classifiers import Classifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import CategoricalEncoder\n","from sklearn.impute import SimpleImputer\n","import progressbar\n","import psutil\n","\n","class SklearnWekaWrapper(object):\n","\n","\tdef __init__(self, class_name, options=None):\n","\n","\t\tif options is not None:\n","\t\t\tself._classifier = Classifier(classname=class_name, options=[option for option in options.split()])\n","\t\telse:\n","\t\t\tself._classifier = Classifier(classname=class_name)\n","\n","\tdef fit(self, training_set, ground_through):\n","\n","\t\tself.ground_through = ground_through\n","\n","\t\ttraining_set = self._sklearn2weka(training_set, self.ground_through)\n","\t\ttraining_set.class_is_last()\n","\n","\t\tself._classifier.build_classifier(training_set)\n","\n","\tdef predict(self, testing_set):\n","\n","\t\ttesting_set = self._sklearn2weka(testing_set, self.ground_through)\n","\t\ttesting_set.class_is_last()\n","\n","\t\tpreds = []\n","\t\tfor index, inst in enumerate(testing_set):\n","\t\t\tpred = self._classifier.classify_instance(inst)\n","\t\t\tpreds.append(pred)\n","\n","\t\tpreds = np.vectorize(self._dict.get)(preds)\n","\n","\t\treturn np.array(preds)\n","\n","\tdef predict_proba(self, testing_set):\n","\n","\t\ttesting_set = self._sklearn2weka(testing_set, self.ground_through)\n","\t\ttesting_set.class_is_last()\n","\n","\t\tdists = []\n","\t\tfor index, inst in enumerate(testing_set):\n","\t\t\tdist = self._classifier.distribution_for_instance(inst)\n","\t\t\tdists.append(dist)\n","\n","\t\treturn np.array(dists)\n","\n","\tdef _sklearn2weka(self, features, labels=None):\n","\n","\t\tencoder = CategoricalEncoder(encoding='ordinal')\n","\t\tlabels_nominal = encoder.fit_transform(np.array(labels).reshape(-1, 1))\n","\n","\t\tif not hasattr(self, 'dict') and labels is not None:\n","\n","\t\t\tdict = {}\n","\n","\t\t\tfor label, nominal in zip(labels, labels_nominal):\n","\t\t\t\tif nominal.item(0) not in dict:\n","\t\t\t\t\tdict[nominal.item(0)] = label\n","\n","\t\t\tself._dict = dict\n","\n","\t\tlabels_column = np.reshape(labels_nominal,[labels_nominal.shape[0], 1])\n","\n","\t\tweka_dataset = ndarray_to_instances(np.ascontiguousarray(features, dtype=np.float_), 'weka_dataset')\n","\t\tweka_dataset.insert_attribute(Attribute.create_nominal('tag', [str(float(i)) for i in range(len(self._dict))]), features.shape[1])\n","\n","\t\tif labels is not None:\n","\t\t\tfor index, inst in enumerate(weka_dataset):\n","\t\t\t\tinst.set_value(features.shape[1], labels_column[index])\n","\t\t\t\tweka_dataset.set_instance(index,inst)\n","\n","\t\treturn weka_dataset\n","\n","class FlatClassifier(object):\n","\tdef __init__(self, input_file, levels_number, level_target, features_number, packets_number, classifier_name):\n","\n","\t\tself.input_file = input_file\n","\t\tself.levels_number = levels_number\n","\t\tself.level_target = level_target\n","\t\tself.features_number = features_number\n","\t\tself.packets_number = packets_number\n","\t\tself.classifier_name = classifier_name\n","\t\tself.tag_under_test = level_target-1\n","\n","\tdef kfold_validation(self, k=10):\n","\n","\t\tavailable_ram = psutil.virtual_memory()[1]\n","\t\tavailable_ram = int(int(available_ram) * .9 * 1e-9)\n","\n","\t\tif available_ram > 5:\n","\t\t\tjvm.start(max_heap_size='5g')\n","\t\telse:\n","\t\t\tprint('Seem your machine has less than 5 GB amount of RAM available:\\n')\n","\t\t\tprint('cannot start jvm.')\n","\t\t\tsys.exit()\n","\n","\t\t###\n","\n","\t\tprint('\\nCaricando '+self.input_file+' con opts -f'+str(self.features_number)+' -c'+self.classifier_name+'\\n')\n","\t\t# load .arff file\n","\t\tdataset = arff.load(open(input_file, 'r'))\n","\t\tdata = np.array(dataset['data'])\n","\n","\t\tself.features_names = [x[0] for x in dataset['attributes']]\n","\n","\t\tself.attributes_number = data.shape[1]\n","\t\tself.dataset_features_number = self.attributes_number - self.levels_number\n","\n","\t\t# Factorization of Nominal features_index\n","\t\tencoder = CategoricalEncoder(encoding='ordinal')\n","\t\tnominal_features_index = [i for i in range(len(dataset['attributes'][:-self.levels_number])) if dataset['attributes'][i][1] != u'NUMERIC']\n","\t\tif len(nominal_features_index) > 0:\n","\t\t\tdata[:, nominal_features_index] = encoder.fit_transform(\n","\t\t\t\tdata[:, nominal_features_index])\n","\n","\t\tprediction = []\n","\t\tprobability = []\n","\t\toracle = []\n","\n","\t\tprint('\\n***\\nStart testing with ' + str(k)+'Fold cross-validation -f'+str(self.features_number)+' -c'+self.classifier_name+'\\n***\\n')\n","\n","\t\tbar = progressbar.ProgressBar(maxval=k, widgets=[progressbar.Bar(\n","\t\t\t'=', '[', ']'), ' ', progressbar.Percentage()])\n","\t\tbar.start()\n","\n","\t\ttemp_metrics = []\n","\n","\t\tskf = StratifiedKFold(n_splits=k, shuffle=True)\n","\t\tbar_cnt = 0\n","\t\tfor train_index, test_index in skf.split(data, data[:, self.dataset_features_number + self.tag_under_test]):\n","\n","\t\t\tself.training_set = data[train_index, :self.dataset_features_number]\n","\t\t\tself.testing_set = data[test_index, :self.dataset_features_number]\n","\t\t\tself.ground_through = data[train_index,\n","\t\t\t\t\t\t\t\t\t   self.dataset_features_number + self.tag_under_test]\n","\t\t\tself.oracle = data[test_index,\n","\t\t\t\t\t\t\t   self.dataset_features_number + self.tag_under_test]\n","\t\t\tself.prediction = np.ndarray(\n","\t\t\t\tshape=[len(test_index), 1], dtype='<U24')\n","\t\t\tself.probability = np.ndarray(\n","\t\t\t\tshape=[len(test_index), len(set(self.ground_through))], dtype='<U24')\n","\n","\t\t\tclassifier_to_call = getattr(self, supported_classifiers[self.classifier_name])\n","\t\t\tclassifier_to_call()\n","\n","\t\t\tprediction.append(self.prediction)\n","\t\t\tprobability.append(self.probability)\n","\t\t\toracle.append(self.oracle)\n","\n","\t\t\tbar_cnt += 1\n","\t\t\tbar.update(bar_cnt)\n","\n","\t\tbar.finish()\n","\n","\t\trelations = []\n","\n","\t\trelations = []\n","\t\trelations.append({  # Lv2:Lv1\n","\t\t\tu'Tor': u'Tor',\n","\t\t\tu'TorPT': u'Tor',\n","\t\t\tu'TorApp': u'Tor',\n","\t\t\tu'I2PApp80BW': u'I2P',\n","\t\t\tu'I2PApp0BW': u'I2P',\n","\t\t\tu'I2PApp': u'I2P',\n","\t\t\tu'JonDonym': u'JonDonym'\n","\t\t})\n","\n","\t\trelations.append({  # Lv3:Lv2\n","\t\t\tu'JonDonym': u'JonDonym',\n","\t\t\tu'I2PSNARK_App80BW': u'I2PApp80BW',\n","\t\t\tu'IRC_App80BW': u'I2PApp80BW',\n","\t\t\tu'Eepsites_App80BW': u'I2PApp80BW',\n","\t\t\tu'I2PSNARK_App0BW': u'I2PApp0BW',\n","\t\t\tu'IRC_App0BW': u'I2PApp0BW',\n","\t\t\tu'Eepsites_App0BW': u'I2PApp0BW',\n","\t\t\tu'I2PSNARK_App': u'I2PApp',\n","\t\t\tu'IRC_App': u'I2PApp',\n","\t\t\tu'Eepsites_App': u'I2PApp',\n","\t\t\tu'ExploratoryTunnels_App': u'I2PApp',\n","\t\t\tu'ParticipatingTunnels_App': u'I2PApp',\n","\t\t\tu'Tor': u'Tor',\n","\t\t\tu'Streaming': u'TorApp',\n","\t\t\tu'Torrent': u'TorApp',\n","\t\t\tu'Browsing': u'TorApp',\n","\t\t\tu'Flashproxy': u'TorPT',\n","\t\t\tu'FTE': u'TorPT',\n","\t\t\tu'Meek': u'TorPT',\n","\t\t\tu'Obfs3': u'TorPT',\n","\t\t\tu'scramblesuit': u'TorPT'\n","\t\t})\n","\n","\t\toracle_inferred = []\n","\t\tprediction_inferred = []\n","\n","\t\tfor i in range(self.tag_under_test):\n","\t\t\toracle_inferred.append(list())\n","\t\t\tprediction_inferred.append(list())\n","\n","\t\t# Infering superior levels\n","\t\tfor i in range(k):\n","\t\t\t# Assign of prediction to a dummy to use this one in consecutive label swaps\n","\t\t\tinferred_prediction = prediction[i].copy()\n","\t\t\tinferred_oracle = oracle[i].copy()\n","\t\t\tfor j in reversed(range(self.tag_under_test)):\n","\t\t\t\tinferred_oracle = np.vectorize(\n","\t\t\t\t\trelations[j].get)(list(inferred_oracle))\n","\t\t\t\tinferred_prediction = np.vectorize(\n","\t\t\t\t\trelations[j].get)(list(inferred_prediction))\n","\t\t\t\toracle_inferred[j].append(inferred_oracle)\n","\t\t\t\tprediction_inferred[j].append(inferred_prediction)\n","\t\tprint('\\n***\\nStart testing with incremental gamma threshold\\n***\\n')\n","\n","\t\tbar = progressbar.ProgressBar(maxval=9, widgets=[progressbar.Bar(\n","\t\t\t'=', '[', ']'), ' ', progressbar.Percentage()])\n","\t\tbar.start()\n","\n","\t\toracle_gamma = []\n","\t\tprediction_gamma = []\n","\t\tclassified_ratio = []\n","\n","\t\tfor i in range(9):\n","\t\t\tgamma = float(i+1)/10.0\n","\n","\t\t\toracle_gamma.append(list())\n","\t\t\tprediction_gamma.append(list())\n","\t\t\tclassified_ratio.append(list())\n","\n","\t\t\tfor j in range(k):\n","\t\t\t\tindexes = []\n","\t\t\t\tp_cnt = 0\n","\t\t\t\tfor p in probability[j]:\n","\t\t\t\t\tif max(p) < gamma:\n","\t\t\t\t\t\tindexes.append(p_cnt)\n","\t\t\t\t\tp_cnt += 1\n","\t\t\t\tgamma_oracle = np.delete(oracle[j], [indexes])\n","\t\t\t\tgamma_prediction = np.delete(prediction[j], [indexes])\n","\t\t\t\toracle_gamma[i].append(gamma_oracle)\n","\t\t\t\tprediction_gamma[i].append(gamma_prediction)\n","\t\t\t\tclassified_ratio[i].append(\n","\t\t\t\t\tfloat(len(gamma_prediction))/float(len(prediction[j])))\n","\n","\t\t\tbar.update(i)\n","\n","\t\tbar.finish()\n","\n","\t\tdata_folder = './data_'+self.classifier_name+'/material/'\n","\n","\t\tif not os.path.exists('./data_'+self.classifier_name):\n","\t\t\tos.makedirs('./data_'+self.classifier_name)\n","\t\t\tos.makedirs(data_folder)\n","\t\telif not os.path.exists(data_folder):\n","\t\t\tos.makedirs(data_folder)\n","\n","\t\tif self.packets_number != 0:\n","\t\t\tfile = open(data_folder+'flat_early_level_'+str(self.level_target) +\n","\t\t\t\t\t\t'_p_'+str(self.packets_number)+'.dat', 'w+')\n","\t\telse:\n","\t\t\tfile = open(data_folder+'flat_flow_level_'+str(self.level_target) +\n","\t\t\t\t\t\t'_f_'+str(self.features_number)+'.dat', 'w+')\n","\n","\t\tfor i in range(k):\n","\t\t\tfile.write('@fold\\n')\n","\t\t\tfor o, p in zip(oracle[i], prediction[i]):\n","\t\t\t\tfile.write(str(o)+' '+str(p)+'\\n')\n","\n","\t\tfile.close()\n","\n","\t\tfor i in range(self.tag_under_test):\n","\n","\t\t\tif self.packets_number != 0:\n","\t\t\t\tfile = open(data_folder+'flat_early_level_'+str(self.level_target) +\n","\t\t\t\t\t\t\t'_p_'+str(self.packets_number)+'_inferred_'+str(i+1)+'.dat', 'w+')\n","\t\t\telse:\n","\t\t\t\tfile = open(data_folder+'flat_flow_level_'+str(self.level_target) +\n","\t\t\t\t\t\t\t'_f_'+str(self.features_number)+'_inferred_'+str(i+1)+'.dat', 'w+')\n","\n","\t\t\tfor j in range(k):\n","\t\t\t\tfile.write('@fold\\n')\n","\t\t\t\tfor o, p in zip(oracle_inferred[i][j], prediction_inferred[i][j]):\n","\t\t\t\t\tfile.write(str(o)+' '+str(p)+'\\n')\n","\n","\t\t\tfile.close()\n","\n","\t\tfor i in range(9):\n","\t\t\tif self.packets_number != 0:\n","\t\t\t\tfile = open(data_folder+'flat_early_level_'+str(self.level_target)+'_p_' +\n","\t\t\t\t\t\t\tstr(self.packets_number)+'_gamma_'+str(float(i+1)/10.0)+'.dat', 'w+')\n","\t\t\telse:\n","\t\t\t\tfile = open(data_folder+'flat_flow_level_'+str(self.level_target)+'_f_' +\n","\t\t\t\t\t\t\tstr(self.features_number)+'_gamma_'+str(float(i+1)/10.0)+'.dat', 'w+')\n","\n","\t\t\tfor j in range(k):\n","\t\t\t\tfile.write('@fold_cr\\n')\n","\t\t\t\tfile.write(str(classified_ratio[i][j])+'\\n')\n","\t\t\t\tfor o, p in zip(oracle_gamma[i][j], prediction_gamma[i][j]):\n","\t\t\t\t\tfile.write(str(o)+' '+str(p)+'\\n')\n","\n","\t\t\tfile.close()\n","\n","\t\t###\n","\n","\t\tjvm.stop()\n","\n","\tdef features_selection(self):\n","\n","\t\tfeatures_index = []\n","\n","\t\tif self.features_number != 0 and self.features_number != self.dataset_features_number:\n","\n","\t\t\tselector = SelectKBest(mutual_info_classif, k=self.features_number)\n","\t\t\ttraining_set_selected = selector.fit_transform(\n","\t\t\t\tself.training_set[:, :self.dataset_features_number], self.ground_through)\n","\t\t\ttraining_set_reconstr = selector.inverse_transform(\n","\t\t\t\ttraining_set_selected)\n","\n","\t\t\ti0 = 0\n","\t\t\ti1 = 0\n","\t\t\twhile i0 < self.features_number:\n","\t\t\t\tif np.array_equal(training_set_selected[:, i0], training_set_reconstr[:, i1]):\n","\t\t\t\t\tfeatures_index.append(i1)\n","\t\t\t\t\ti0 += 1\n","\t\t\t\ti1 += 1\n","\t\telse:\n","\t\t\tif self.packets_number == 0:\n","\t\t\t\tfeatures_index = [i for i in range(self.dataset_features_number)]\n","\t\t\telse:\n","\t\t\t\tfeatures_index = np.r_[0:self.packets_number, self.dataset_features_number /\n","\t\t\t\t\t2:self.dataset_features_number/2+self.packets_number]\n","\n","\t\treturn features_index\n","\n","\tdef Sklearn_RandomForest(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef Sklearn_CART(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = DecisionTreeClassifier()\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef Weka_NaiveBayes(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = SklearnWekaWrapper(class_name='weka.classifiers.bayes.NaiveBayes', options='-D')\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef Weka_BayesNetwork(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = SklearnWekaWrapper(class_name='weka.classifiers.bayes.BayesNet', options='-D -Q weka.classifiers.bayes.net.search.local.TAN -- -S BAYES -E weka.classifiers.bayes.net.estimate.SimpleEstimator -- -A 0.5')\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef Weka_RandomForest(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = SklearnWekaWrapper(class_name='weka.classifiers.trees.RandomForest')\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef Weka_J48(self):\n","\n","\t\t# Instantation\n","\t\tclassifier = SklearnWekaWrapper(class_name='weka.classifiers.trees.J48')\n","\n","\t\t# Features selection\n","\t\tfeatures_index = self.features_selection()\n","\n","\t\tself.train(classifier, features_index)\n","\t\tself.test(classifier, features_index)\n","\n","\tdef train(self, classifier, features_index):\n","\n","\t\tclassifier.fit(self.training_set[:, features_index], self.ground_through)\n","\n","\tdef test(self, classifier, features_index):\n","\n","\t\tself.prediction = classifier.predict(\n","\t\t\tself.testing_set[:, features_index])\n","\t\tself.probability = classifier.predict_proba(\n","\t\t\tself.testing_set[:, features_index])\n","\n","if __name__ == \"__main__\":\n","\tos.environ[\"DISPLAY\"] = \":0\"  # used to show xming display\n","\tnp.random.seed(0)\n","\n","\tsupported_classifiers = {\n","\t\t'srf': 'Sklearn_RandomForest',\n","\t\t'scr': 'Sklearn_CART',\n","\t\t'wnb': 'Weka_NaiveBayes',\n","\t\t'wbn': 'Weka_BayesNetwork',\n","\t\t'wrf': 'Weka_RandomForest',\n","\t\t'wj48': 'Weka_J48'\n","\t}\n","\n","\tinput_file = ''\n","\tlevels_number = 0\n","\tlevel_target = 0\n","\tfeatures_number = 0\n","\tpackets_number = 0\n","\tclassifier_name = 'srf'\n","\n","\ttry:\n","\t\topts, args = getopt.getopt(\n","\t\t\tsys.argv[1:], \"hi:n:t:f:p:c:\", \"[input_file=,levels_number=,level_target=,features_number=,packets_number=,classifier=]\")\n","\texcept getopt.GetoptError:\n","\t\tprint('FlatClassifier.py -i <input_file> -n <levels_number> -t <level_target> (-f <features_number>|-p <packets_number>) -c <classifier_name>')\n","\t\tprint('FlatClassifier.py -h (or --help) for a carefuler help')\n","\t\tsys.exit(2)\n","\tfor opt, arg in opts:\n","\t\tif opt in (\"-h\", \"--help\"):\n","\t\t\tprint('FlatClassifier.py -i <input_file> -n <levels_number> -t <level_target> (-f <features_number>|-p <packets_number>) -c <classifier_name>\\n')\n","\t\t\tprint('Options:\\n\\t-i: dataset file, must be in arff format\\n\\t-n: number of levels (number of labels\\' columns)\\n\\t-t: level target of classification, count of levels start from 1')\n","\t\t\tprint('\\t-f or -p: former refers features number, latter refers packets number\\n\\t-c: classifier name choose from following list:')\n","\t\t\tfor sc in supported_classifiers:\n","\t\t\t\tprint('\\t\\t-c '+sc+'\\t--->\\t'+supported_classifiers[sc].split('_')[1]+'\\t\\timplemented in '+supported_classifiers[sc].split('_')[0])\n","\t\t\tsys.exit()\n","\t\tif opt in (\"-i\", \"--input_file\"):\n","\t\t\tinput_file = arg\n","\t\tif opt in (\"-n\", \"--levels_number\"):\n","\t\t\tlevels_number = int(arg)\n","\t\tif opt in (\"-t\", \"--level_target\"):\n","\t\t\tlevel_target = int(arg)\n","\t\tif opt in (\"-f\", \"--nfeat\"):\n","\t\t\tfeatures_number = int(arg)\n","\t\tif opt in (\"-p\", \"--npacket\"):\n","\t\t\tpackets_number = int(arg)\n","\t\tif opt in (\"-c\", \"--clf\"):\n","\t\t\tclassifier_name = arg\n","\n","\tif packets_number != 0 and features_number != 0 or packets_number == features_number:\n","\t\tprint('-f and -p option should not be used together')\n","\t\tsys.exit()\n","\n","\tif levels_number == 0:\n","\t\tprint('Number of level must be positive and non zero')\n","\t\tsys.exit()\n","\n","\tif level_target == 0 or level_target > levels_number:\n","\t\tprint('Level target must be positive, non zero and less than or equal to levels_number')\n","\t\tsys.exit()\n","\n","\tif not input_file.endswith(\".arff\"):\n","\t\tprint('Input file must be .arff')\n","\t\tsys.exit()\n","\n","\tif classifier_name not in supported_classifiers:\n","\t\tprint('Classifier not supported\\nList of available classifiers:\\n')\n","\t\tfor sc in supported_classifiers:\n","\t\t\tprint('-c '+sc+'\\t--->\\t'+supported_classifiers[sc].split('_')[1]+'\\t\\timplemented in '+supported_classifiers[sc].split('_')[0])\n","\t\tsys.exit()\n","\n","\tflat_classifier = FlatClassifier(input_file=input_file,levels_number=levels_number,level_target=level_target,features_number=features_number,packets_number=packets_number,classifier_name=classifier_name)\n","\tflat_classifier.kfold_validation(k=10)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO7+cjFOoXe+VNUmDj6jJtL","name":"NM2 Flat Classifier.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit (windows store)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10"},"vscode":{"interpreter":{"hash":"938c77f67827b4d620c51952f1f2e540ff7e6645682ba4f9dcac788fd6bea7e6"}}},"nbformat":4,"nbformat_minor":0}
